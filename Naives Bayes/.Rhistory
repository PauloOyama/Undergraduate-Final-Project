next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
words = tokenize(train[i,1])
words
token_frequency <- function(train){
table_frequency <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
for (j in 1:length(words)){
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
return (table_frequency)
}
set.seed(3)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
i
rm(i)
rm(j)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
table_frequency <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
for (j in 1:length(words)){
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
train[i,]
words
tokenize(1  date wed NUMBER aug NUMBER NUMBER NUMBER NUMBER NUMBER from chris garrigues cwg dated NUMBER NUMBERfaNUMBERd deepeddy com message id NUMBER NUMBER tmda deepeddy vircio com i can t reproduce this error for me it is very repeatable like every time without fail this is the debug log of the pick happening NUMBER NUMBER NUMBER pick_it exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER ftoc_pickmsgs NUMBER hit NUMBER NUMBER NUMBER marking NUMBER hits NUMBER NUMBER NUMBER tkerror syntax error in expression int note if i run the pick command by hand delta pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER hit that s where the NUMBER hit comes from obviously the version of nmh i m using is delta pick version pick nmh NUMBER NUMBER NUMBER compiled on URL at sun mar NUMBER NUMBER NUMBER NUMBER ict NUMBER and the relevant part of my mh_profile delta mhparam pick seq sel list since the pick command works the sequence actually both of them the one that s explicit on the command line from the search popup and the one that comes from mh_profile do get created kre ps this is still using the version of the code form a day ago i haven t been able to reach the cvs repository today local routing issue i think _______________________________________________ exmh workers mailing list exmh workers URL URL)
tokenize("1  date wed NUMBER aug NUMBER NUMBER NUMBER NUMBER NUMBER from chris garrigues cwg dated NUMBER NUMBERfaNUMBERd deepeddy com message id NUMBER NUMBER tmda deepeddy vircio com i can t reproduce this error for me it is very repeatable like every time without fail this is the debug log of the pick happening NUMBER NUMBER NUMBER pick_it exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER ftoc_pickmsgs NUMBER hit NUMBER NUMBER NUMBER marking NUMBER hits NUMBER NUMBER NUMBER tkerror syntax error in expression int note if i run the pick command by hand delta pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER hit that s where the NUMBER hit comes from obviously the version of nmh i m using is delta pick version pick nmh NUMBER NUMBER NUMBER compiled on URL at sun mar NUMBER NUMBER NUMBER NUMBER ict NUMBER and the relevant part of my mh_profile delta mhparam pick seq sel list since the pick command works the sequence actually both of them the one that s explicit on the command line from the search popup and the one that comes from mh_profile do get created kre ps this is still using the version of the code form a day ago i haven t been able to reach the cvs repository today local routing issue i think _______________________________________________ exmh workers mailing list exmh workers URL URL")
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(msg,"[[:space:]]")[[1]][!words_dup]
return (tokens)
}
tokenize("1  date wed NUMBER aug NUMBER NUMBER NUMBER NUMBER NUMBER from chris garrigues cwg dated NUMBER NUMBERfaNUMBERd deepeddy com message id NUMBER NUMBER tmda deepeddy vircio com i can t reproduce this error for me it is very repeatable like every time without fail this is the debug log of the pick happening NUMBER NUMBER NUMBER pick_it exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER ftoc_pickmsgs NUMBER hit NUMBER NUMBER NUMBER marking NUMBER hits NUMBER NUMBER NUMBER tkerror syntax error in expression int note if i run the pick command by hand delta pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER hit that s where the NUMBER hit comes from obviously the version of nmh i m using is delta pick version pick nmh NUMBER NUMBER NUMBER compiled on URL at sun mar NUMBER NUMBER NUMBER NUMBER ict NUMBER and the relevant part of my mh_profile delta mhparam pick seq sel list since the pick command works the sequence actually both of them the one that s explicit on the command line from the search popup and the one that comes from mh_profile do get created kre ps this is still using the version of the code form a day ago i haven t been able to reach the cvs repository today local routing issue i think _______________________________________________ exmh workers mailing list exmh workers URL URL")
tokens[nchar(words)>3]
[[nchar(words)>3]
tokens[nchar(tokens)>3]
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(msg,"[[:space:]]")[[1]][!words_dup]
tokens = tokens[nchar(tokens)>3]
return (tokens)
}
token_frequency <- function(train){
table_frequency <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
for (j in 1:length(words)){
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
return (table_frequency)
}
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
rm(i)
rm(j)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
words
words[j]
train[60,]
table_frequency[60,]
table_frequency[59,]
token_frequency <- function(train){
table_frequency <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
for (j in 1:length(words)){
print(words[j])
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
return (table_frequency)
}
set.seed(3)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
rm(i)
rm(j)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
token_frequency <- function(train){
table_frequency <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
print(i)
for (j in 1:length(words)){
print(j)
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
return (table_frequency)
}
set.seed(3)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
rm(i)
rm(j)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
train[559,]
NA == NA
NA == NA
NA == 1
is.na(NA)
token_frequency <- function(train){
table_frequency <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
if(is.na(words)){
next
}
for (j in 1:length(words)){
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
return (table_frequency)
}
set.seed(3)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
rm(i)
rm(j)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
train[55,9]
train[559,]
tokenize(train[559,])
tokenize(train[559,1])
tokenize(train[558,1])
tokenize(train[559,1])
train[559,1]
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(msg,"[[:space:]]")[[1]][!words_dup]
return (tokens)
}
tokenize(train[559,1])
class(tokenize(train[559,1]))
is.character(character(0))
is.character(character(1))
is.character(character(2))
character(0)
length(character(0))
length(character(0)) == 0
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(msg,"[[:space:]]")[[1]][!words_dup]
tokens = tokens[nchar(tokens)>3]
return (tokens)
}
token_frequency <- function(train){
table_frequency <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
if(length(words) == 0){
next
}
for (j in 1:length(words)){
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% table_frequency$words){
if(train[i,2] == 0){
table_frequency$ham[table_frequency$words == words[j]] = table_frequency$ham[table_frequency$words == words[j]] + 1
}else{
table_frequency$spam[table_frequency$words == words[j]] = table_frequency$spam[table_frequency$words == words[j]] + 1
}
}else{
table_frequency[nrow(table_frequency)+1,1] = c(words[j])
if(train[i,2] == 0){
table_frequency[nrow(table_frequency),2] = c(0)
table_frequency[nrow(table_frequency),3] = c(1)
}else{
table_frequency[nrow(table_frequency),2] = c(1)
table_frequency[nrow(table_frequency),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
return (table_frequency)
}
set.seed(3)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
rm(i)
rm(j)
#Creating a table with the frequency of each token given spam or not spam
table_frequency <- token_frequency(train)
#creating a column for the probability of each word given spam or not spam
for(i in 1:nrow(table_frequency)){
table_frequency$p_spam[i] = table_frequency$spam[i]/spam
table_frequency$p_ham[i] = table_frequency$ham[i]/not_spam
}
table_frequency$p_spam
#Testing the created model
for(i in 1:nrow(test)){
words <- tokenize(test[i,1])
#probability of all the words be spam
probability_spam = 0
for (j in 1:length(words)){
p_word = table_frequency$p_spam[table_frequency$words == words[j]]
if(words[j] %in% table_frequency$words && p_word != 0){
probability_spam = probability_spam + log(p_word)
}else{
next
}
}
#probability of all the words not be spam
probability_ham = 0
for (j in 1:length(words)){
p_word = table_frequency$p_ham[table_frequency$words == words[j]]
if(words[j] %in% table_frequency$words && p_word != 0){
probability_ham = probability_ham + log(p_word)
}else{
next
}
}
print("----------------")
upper <- probability_spam+log(p_spam)
print(upper)
lower <- probability_spam+log(p_spam) + probability_ham+log(p_not_spam)
print(lower)
test$prob[i] <-  ifelse(upper/lower > 0.5, 1, 0)
test$q[i] <- upper/lower
}
#Testing the created model
for(i in 1:nrow(test)){
words <- tokenize(test[i,1])
#probability of all the words be spam
probability_spam = 0
for (j in 1:length(words)){
p_word = table_frequency$p_spam[table_frequency$words == words[j]]
if(words[j] %in% table_frequency$words && p_word != 0){
probability_spam = probability_spam + log(p_word)
}else{
next
}
}
#probability of all the words not be spam
probability_ham = 0
for (j in 1:length(words)){
p_word = table_frequency$p_ham[table_frequency$words == words[j]]
if(words[j] %in% table_frequency$words && p_word != 0){
probability_ham = probability_ham + log(p_word)
}else{
next
}
}
print("----------------")
upper <- probability_spam+log(p_spam)
lower <- probability_spam+log(p_spam) + probability_ham+log(p_not_spam)
test$predict[i] <-  ifelse(upper/lower > 0.5, 1, 0)
test$probability[i] <- upper/lower
}
#Testing the created model
for(i in 1:nrow(test)){
words <- tokenize(test[i,1])
#probability of all the words be spam
probability_spam = 0
for (j in 1:length(words)){
p_word = table_frequency$p_spam[table_frequency$words == words[j]]
if(words[j] %in% table_frequency$words && p_word != 0){
probability_spam = probability_spam + log(p_word)
}else{
next
}
}
#probability of all the words not be spam
probability_ham = 0
for (j in 1:length(words)){
p_word = table_frequency$p_ham[table_frequency$words == words[j]]
if(words[j] %in% table_frequency$words && p_word != 0){
probability_ham = probability_ham + log(p_word)
}else{
next
}
}
upper <- probability_spam+log(p_spam)
lower <- probability_spam+log(p_spam) + probability_ham+log(p_not_spam)
test$predict[i] <-  ifelse(upper/lower > 0.5, 1, 0)
test$probability[i] <- upper/lower
}
words[j] %in% table_frequency$words && p_word != 0
p_word
table_frequency$p_ham[table_frequency$words == words[j]]
