setwd("A:/Universidade/TCC/Implementação/Naives Bayes")
df = read.csv("data/spam_or_not_spam.csv")
lb = read.table(file="data/stopwords.txt", header=TRUE)
lb
set.seed(1)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam in relational with the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
lb$a
lb
lb[nrow(lb)+1,] = 'a'
lb
words[1] %in% lb$a
words[1] %in% lb$a
#find duplicated values
words_dup = duplicated(strsplit(train[i,1],"[[:space:]]")[[1]])
#take the distinct value
words = strsplit(train[i,1],"[[:space:]]")[[1]][!words_dup]
for (i in 1:nrow(train)){
if(train[i,1] == ""){
next
}
#find duplicated values
words_dup = duplicated(strsplit(train[i,1],"[[:space:]]")[[1]])
#take the distinct value
words = strsplit(train[i,1],"[[:space:]]")[[1]][!words_dup]
for (j in 1:length(words)){
if(words[j] %in% lb$a){
next
}
if(words[j] %in% df2$words){
if(train[i,2] == 0){
df2$ham[df2$words == words[j]] = df2$ham[df2$words == words[j]] + 1
}else{
df2$spam[df2$words == words[j]] = df2$spam[df2$words == words[j]] + 1
}
}else{
df2[nrow(df2)+1,1] = c(words[j])
if(train[i,2] == 0){
df2[nrow(df2),2] = c(0)
df2[nrow(df2),3] = c(1)
}else{
df2[nrow(df2),2] = c(1)
df2[nrow(df2),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
#Time to code
df2 <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
if(train[i,1] == ""){
next
}
#find duplicated values
words_dup = duplicated(strsplit(train[i,1],"[[:space:]]")[[1]])
#take the distinct value
words = strsplit(train[i,1],"[[:space:]]")[[1]][!words_dup]
for (j in 1:length(words)){
if(words[j] %in% lb$a){
next
}
if(words[j] %in% df2$words){
if(train[i,2] == 0){
df2$ham[df2$words == words[j]] = df2$ham[df2$words == words[j]] + 1
}else{
df2$spam[df2$words == words[j]] = df2$spam[df2$words == words[j]] + 1
}
}else{
df2[nrow(df2)+1,1] = c(words[j])
if(train[i,2] == 0){
df2[nrow(df2),2] = c(0)
df2[nrow(df2),3] = c(1)
}else{
df2[nrow(df2),2] = c(1)
df2[nrow(df2),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
df2$words
for(i in 1:nrow(df2)){
df2$p_spam[i] = df2$spam[i]/spam
df2$p_ham[i] = df2$ham[i]/not_spam
}
df2
df2
for(i in 1:nrow(test)){
#find duplicated values
words_dup = duplicated(strsplit(test[i,1],"[[:space:]]")[[1]])
#take the distinct value
words = strsplit(test[i,1],"[[:space:]]")[[1]][!words_dup]
#spam
probability_spam = 1
for (j in 1:length(words)){
wd = df2$p_spam[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_spam = probability_spam * log(df2$p_spam[df2$words == words[j]])
}else{
next
}
}
#ham
probability_ham = 1
for (j in 1:length(words)){
wd = df2$p_ham[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_ham = probability_ham * log(df2$p_ham[df2$words == words[j]])
}else{
next
}
}
upper <- probability_spam*log(p_spam)
lower <- probability_ham*log(p_not_spam)
test$prob[i] <-  ifelse(upper/lower > 0.80, 1, 0)
}
install.packages('caret')
library(caret)
example <- confusionMatrix(data=test$prob, reference = test$label)
example <- confusionMatrix(data=as.Factor(test$prob), reference = as.Factor(test$label))
example <- confusionMatrix(data=as.factor(test$prob), reference = as.factor(test$label))
example
test$prob
for(i in 1:nrow(test)){
#find duplicated values
words_dup = duplicated(strsplit(test[i,1],"[[:space:]]")[[1]])
#take the distinct value
words = strsplit(test[i,1],"[[:space:]]")[[1]][!words_dup]
#spam
probability_spam = 1
for (j in 1:length(words)){
wd = df2$p_spam[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_spam = probability_spam * log(df2$p_spam[df2$words == words[j]])
}else{
next
}
}
#ham
probability_ham = 1
for (j in 1:length(words)){
wd = df2$p_ham[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_ham = probability_ham * log(df2$p_ham[df2$words == words[j]])
}else{
next
}
}
upper <- probability_spam*log(p_spam)
lower <- probability_ham*log(p_not_spam)
test$prob[i] <-  ifelse(upper/lower > 0.80, 1, 0)
test$q <- upper/lower
}
test
test[i,]
probability_spam = 1
for (j in 1:length(words)){
wd = df2$p_spam[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_spam = probability_spam * log(df2$p_spam[df2$words == words[j]])
}else{
next
}
}
probability_ham = 1
for (j in 1:length(words)){
wd = df2$p_ham[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_ham = probability_ham * log(df2$p_ham[df2$words == words[j]])
}else{
next
}
}
upper <- probability_spam*log(p_spam)
lower <- probability_ham*log(p_not_spam)
#spam
probability_spam = 1
for (j in 1:length(words)){
wd = df2$p_spam[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_spam = probability_spam * log(df2$p_spam[df2$words == words[j]])
print(probability_spam)
}else{
next
}
}
test$email[2]
#spam
probability_spam = 0
for (j in 1:length(words)){
wd = df2$p_spam[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_spam = probability_spam + log(df2$p_spam[df2$words == words[j]])
print(probability_spam)
}else{
next
}
}
#ham
probability_ham = 0
for (j in 1:length(words)){
wd = df2$p_ham[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_ham = probability_ham + log(df2$p_ham[df2$words == words[j]])
}else{
next
}
}
upper <- probability_spam+log(p_spam)
lower <- probability_ham+log(p_not_spam)
test$prob[i] <-  ifelse(upper/lower > 0.80, 1, 0)
test$q <- upper/lower
test[nrow(test),]
for(i in 1:nrow(test)){
#find duplicated values
words_dup = duplicated(strsplit(test[i,1],"[[:space:]]")[[1]])
#take the distinct value
words = strsplit(test[i,1],"[[:space:]]")[[1]][!words_dup]
#spam
probability_spam = 0
for (j in 1:length(words)){
wd = df2$p_spam[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_spam = probability_spam + log(df2$p_spam[df2$words == words[j]])
print(probability_spam)
}else{
next
}
}
#ham
probability_ham = 0
for (j in 1:length(words)){
wd = df2$p_ham[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_ham = probability_ham + log(df2$p_ham[df2$words == words[j]])
}else{
next
}
}
upper <- probability_spam+log(p_spam)
lower <- probability_ham+log(p_not_spam)
test$prob[i] <-  ifelse(upper/lower > 0.5, 1, 0)
test$q <- upper/lower
}
for(i in 1:nrow(test)){
#find duplicated values
words_dup = duplicated(strsplit(test[i,1],"[[:space:]]")[[1]])
#take the distinct value
words = strsplit(test[i,1],"[[:space:]]")[[1]][!words_dup]
#spam
probability_spam = 0
for (j in 1:length(words)){
wd = df2$p_spam[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_spam = probability_spam + log(df2$p_spam[df2$words == words[j]])
}else{
next
}
}
#ham
probability_ham = 0
for (j in 1:length(words)){
wd = df2$p_ham[df2$words == words[j]]
if(words[j] %in% df2$words && wd != 0){
probability_ham = probability_ham + log(df2$p_ham[df2$words == words[j]])
}else{
next
}
}
upper <- probability_spam+log(p_spam)
lower <- probability_spam+log(p_spam) + probability_ham+log(p_not_spam)
test$prob[i] <-  ifelse(upper/lower > 0.5, 1, 0)
test$q <- upper/lower
}
test[nrow(test),]
example <- confusionMatrix(data=as.factor(test$prob), reference = as.factor(test$label))
example
tokinize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(train[i,1],"[[:space:]]")[[1]][!words_dup]
return (tokens)
}
tokenize("A A A AA A  A")
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(train[i,1],"[[:space:]]")[[1]][!words_dup]
return (tokens)
}
tokenize("A A A AA A  A")
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(msg,"[[:space:]]")[[1]][!words_dup]
return (tokens)
}
tokenize("A A A AA A  A")
a <- tokenize("A A A AA A  A")
class(a)
a
a
df <- data.frame(token=c(""),spam=c(0),not_spam=c(0))
words = tokenize(msg)
tokenFrequencyDF <- function(msg){
df <- data.frame(token=c(""),spam=c(0),not_spam=c(0))
tokens = tokenize(msg)
for (j in 1:length(tokens)){
if(tokens[j] %in% stopwords$a){
next
}
if(tokens[j] %in% df$token){
if(train[i,2] == 0){
df$ham[df$token == tokens[j]] = df$not_spam[df$token == tokens[j]] + 1
}else{
df$spam[df$token == tokens[j]] = df$spam[df$token == tokens[j]] + 1
}
}else{
df2[nrow(df)+1,1] = c(tokens[j])
if(train[i,2] == 0){
df[nrow(df),2] = c(0)
df[nrow(df),3] = c(1)
}else{
df[nrow(df),2] = c(1)
df[nrow(df),3] = c(1)
}
}
}
return(df)
}
df$token
df + df
tokenFrequencyDF <- function(msg,df){
tokens = tokenize(msg)
for (j in 1:length(tokens)){
if(tokens[j] %in% stopwords$a){
next
}
if(tokens[j] %in% df$token){
if(train[i,2] == 0){
df$ham[df$token == tokens[j]] = df$not_spam[df$token == tokens[j]] + 1
}else{
df$spam[df$token == tokens[j]] = df$spam[df$token == tokens[j]] + 1
}
}else{
df2[nrow(df)+1,1] = c(tokens[j])
if(train[i,2] == 0){
df[nrow(df),2] = c(0)
df[nrow(df),3] = c(1)
}else{
df[nrow(df),2] = c(1)
df[nrow(df),3] = c(1)
}
}
}
}
#MAIN
set.seed(1)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
probabilityTable <- data.frame(token=c(""),spam=c(0),not_spam=c(0))
for (i in 1:nrow(train)){
#Messages without any word
#Maybe remove "" and NUMBER string too?
if(train[i,1] == ""){
next
}
tokenFrequencyDF(train[i,1],probabilityTable)
}
df = read.csv("data/spam_or_not_spam.csv")
stopwords = read.table(file="data/stopwords.txt", header=TRUE)
stopwords[nrow(stopwords)+1,] = 'a'
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(msg,"[[:space:]]")[[1]][!words_dup]
return (tokens)
}
tokenFrequencyDF <- function(msg,df){
tokens = tokenize(msg)
for (j in 1:length(tokens)){
if(tokens[j] %in% stopwords$a){
next
}
if(tokens[j] %in% df$token){
if(train[i,2] == 0){
df$ham[df$token == tokens[j]] = df$not_spam[df$token == tokens[j]] + 1
}else{
df$spam[df$token == tokens[j]] = df$spam[df$token == tokens[j]] + 1
}
}else{
df2[nrow(df)+1,1] = c(tokens[j])
if(train[i,2] == 0){
df[nrow(df),2] = c(0)
df[nrow(df),3] = c(1)
}else{
df[nrow(df),2] = c(1)
df[nrow(df),3] = c(1)
}
}
}
}
#MAIN
set.seed(1)
#Dividing in train an test (70,30)
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
#Take the number of spam and non spam
spam = length(train$label[train$label != 0])
not_spam = length(train$label) - spam
#Take the probability of be spam and non spam regarding the total number
p_spam = spam/length(train$label)
p_not_spam = not_spam/length(train$label)
probabilityTable <- data.frame(token=c(""),spam=c(0),not_spam=c(0))
for (i in 1:nrow(train)){
#Messages without any word
#Maybe remove "" and NUMBER string too?
if(train[i,1] == ""){
next
}
tokenFrequencyDF(train[i,1],probabilityTable)
}
probabilityTable
train[2,]
tokenFrequencyDF("2 martin a posted tassos papadopoulos the greek sculptor behind the plan judged that the limestone of mount kerdylio NUMBER miles east of salonika and not far from the mount athos monastic community was ideal for the patriotic sculpture as well as alexander s granite features NUMBER ft high and NUMBER ft wide a museum a restored amphitheatre and car park for admiring crowds are planned so is this mountain limestone or granite if it s limestone it ll weather pretty fast yahoo groups sponsor NUMBER dvds free s p join now URL to unsubscribe from this group send an email to forteana unsubscribe URL your use of yahoo groups is subject to URL", probabilityTable)
tokenFrequencyDF("2 martin a posted tassos papadopoulos the greek sculptor behind the plan judged that the limestone of mount kerdylio NUMBER miles east of salonika and not far from the mount athos monastic community was ideal for the patriotic sculpture as well as alexander s granite features NUMBER ft high and NUMBER ft wide a museum a restored amphitheatre and car park for admiring crowds are planned so is this mountain limestone or granite if it s limestone it ll weather pretty fast yahoo groups sponsor NUMBER dvds free s p join now URL to unsubscribe from this group send an email to forteana unsubscribe URL your use of yahoo groups is subject to URL", probabilityTable)
tokenize <- function(msg){
#find duplicated values in a string
words_dup = duplicated(strsplit(msg,"[[:space:]]")[[1]])
#remove the duplicated values(TOKENS)
tokens = strsplit(msg,"[[:space:]]")[[1]][!words_dup]
return (tokens)
}
tokenize("2 martin a posted tassos papadopoulos the greek sculptor behind the plan judged that the limestone of mount kerdylio NUMBER miles east of salonika and not far from the mount athos monastic community was ideal for the patriotic sculpture as well as alexander s granite features NUMBER ft high and NUMBER ft wide a museum a restored amphitheatre and car park for admiring crowds are planned so is this mountain limestone or granite if it s limestone it ll weather pretty fast yahoo groups sponsor NUMBER dvds free s p join now URL to unsubscribe from this group send an email to forteana unsubscribe URL your use of yahoo groups is subject to URL")
#Time to code
df2 <- data.frame(words=c(""),spam=c(0),ham=c(0))
for (i in 1:nrow(train)){
#Messages without any word
if(train[i,1] == ""){
next
}
words = tokenize(train[i,1])
for (j in 1:length(words)){
if(words[j] %in% stopwords$a){
next
}
if(words[j] %in% df2$words){
if(train[i,2] == 0){
df2$ham[df2$words == words[j]] = df2$ham[df2$words == words[j]] + 1
}else{
df2$spam[df2$words == words[j]] = df2$spam[df2$words == words[j]] + 1
}
}else{
df2[nrow(df2)+1,1] = c(words[j])
if(train[i,2] == 0){
df2[nrow(df2),2] = c(0)
df2[nrow(df2),3] = c(1)
}else{
df2[nrow(df2),2] = c(1)
df2[nrow(df2),3] = c(1)
}
}
}
#Maybe remove "" and NUMBER string ?
}
